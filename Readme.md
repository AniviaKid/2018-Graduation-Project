# 2018毕业设计

包含项目描述，参考文献，项目计划，会议总结等内容。

---

## 项目描述

此项目为基于Arduino的语音控制小车实现。

使用者通过语音发出指令来指示小车的运行，小车接收到指令后执行相应动作，如前进/后退、左转/右转、加速/减速等。

智能小车作为现代发明，在军事、工业制造、生活服务等行业取得了广泛的应用。大部分小车都要求使用者具有一定计算机方面知识来对小车进行操控，这无疑会成为智能小车发展的一大障碍；而使用语音识别技术，可以让绝大多数人无障碍零成本地向小车发出指令。

目前的大部分携带语音识别技术的小车都通过自带专用于语音识别的芯片（如LD3320芯片）来完成语音接收与识别，这在一定程度上增加了小车的成本并降低了可移植性。本项目使用每个人都会随身携带的智能手机作为语音模块，来完成语音的接收与识别。这样降低了小车的硬件成本，同时由于语音模块作为软件存在在手机上，也大大提高了可移植性。

## 项目关键技术

1. 基于卷积神经网络的语音识别技术

   参考文献：

   <a href="https://www.isca-speech.org/archive/interspeech_2015/papers/i15_1478.pdf">Convolutional Neural Networks for Small-footprint Keyword Spotting</a>

   https://www.tensorflow.org/tutorials/sequences/audio_recognition

2. Android环境下通过USB控制Arduino开发板

   参考文献：

   https://www.arduino.cn/thread-7217-1-1.html

## 项目计划

由于考研持续到12月底，预计19年1月正式开始毕设，下学期开学一周内（3月3日前）完成，共计5~6周。

第一周：阅读博客，购买部件组装小车，了解Arduino开发板的使用

第二周：阅读Simple Audio Recognition源码，装载到Android环境下

第三~四周：编码

第五周：实验，debug

## 会议总结

10.26第一次会议：

阅读了两篇论文：《Semantic Parsing with Syntax- and Table-Aware SQL Generation》与《A Survey on Deep Transfer Learning》，第一篇论文提出了一个将自然语言转化为可执行的SQL语言的模型，模型基于Encoder-Decoder框架与Attention Mechanism实现了一个指针网络并将这个指针网络应用于作者提出的新模型——STAMP。

STAMP模型中有三种模式——列名、单元格的值、SQL关键字，模型使用这三种模式来预测不同类型的结果。列名预测结果为表格中存在的列的名称，单元格的值预测结果为表格中cell的value，SQL关键字预测结果为select、where等关键字。此外，作者还通过列-cell之间的关联与策略梯度两种方法来对模型进行优化。

第二篇论文则总结了四种常见的深度迁移学习——基于实例的深度迁移学习、基于映射的深度迁移学习、基于网络的深度迁移学习、基于对抗性技术的深度迁移学习。

受到第一篇论文的启发，我计划利用自然语言->SQL的模型来写一个能够应用与实际生活的app，主要功能为回答使用者的问题，如今日天气、校车路线等有实用价值的情景。

导师认真地听完了我的汇报之后给予了一些点评：首先是数据获取较难，训练出一个可用的模型需要的数据集较为庞大，这要求我能够想出足够多类型的拥有实用价值的问题并且为它们手动标注SQL语言，以此作为训练集来对模型进行训练。其次是目前的开源技术较难以将这项模型应用到实际生活中，模型的准确率不够高。

&nbsp;

10.30第二次会议：

认真吸取了导师的点评之后，我放弃了上一个构思，重新提出了新的构思，也就是这个项目，基于Arduino的语音控制小车实现。导师提出了项目的大致流程，并推荐了参考文献，受益匪浅。

<<<<<<< HEAD
&nbsp;

&nbsp;

##### 2019.1.1_update

控制Arduino开发板实现Blink的示例项目阅读完毕，继续学习Arduino中

开发板及小车部件已购买，等待快递中

=======
####1.1update
控制Arduino开发板实现Blink的示例项目阅读完毕，继续学习Arduino中
开发板及小车部件已购买，等待快递中
>>>>>>> 7ba233f4a662730cc59ad5e86183883197259654
